{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZJFbNjqKjjht"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggMHzU2KtFu3",
        "outputId": "fb653884-9e19-45fc-ee81-e48321693758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device_check: cuda\n"
          ]
        }
      ],
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('device_check:',device) # GPU 사용이 가능하면 cuda 출력 / 불가능하면 cpu 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVgFeSPP72P2"
      },
      "source": [
        "# ※ Section I. PyTorch 이용하여 MLP 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w0CR4zGpm_B"
      },
      "source": [
        "## One-Layer Perceptron 예제\n",
        "### PyTorch에서는 torch.nn.Linear를 이용하여 간단하게 perceptron을 구현할 수 있다.\n",
        "### torch.nn.Linear의 paramters\n",
        "* in_features: input data (2차원 행렬)에서 column의 개수\n",
        "* out_features: output data (2차원 행렬)에서 column의 개수\n",
        "\n",
        "### torch.nn.Linear의 input\n",
        "* input은 [batch_size, row, column] 사이즈를 가진 행렬 형태여야 한다. (row X column 행렬)\n",
        "* batch_size란 row X column 행렬이 독립적으로 몇 개 존재하는지 정도로 이해하도록 한다.\n",
        "* batch_size에 대해 더 궁금한 점은 검색해서 찾아보기\n",
        "\n",
        "### GPU 사용\n",
        "* model = model.to(device) 로 선언한 후\n",
        "* model의 input data 역시 input_data = input_data.to(device)로 선언해주어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t2dPf0epSLV",
        "outputId": "1b46c7b6-5fed-482b-c160-1eed97e497cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 8])\n"
          ]
        }
      ],
      "source": [
        "# nn.Linear 예제\n",
        "\n",
        "one_layer = nn.Linear(3,8).to(device) # nn.Linear(in_features, out_features), 입력 텐서의 크기가 3이고, 출력 텐서의 크기가 8인 선형 변환을 수행하는 nn.Linear 모듈 생성\n",
        "input_data = torch.randn(5,12,3).to(device) # 12 X 3 행렬이 독립적으로 5개 있음을 의미함\n",
        "out = one_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Di8VgkoznrO"
      },
      "source": [
        "## Two-Layer Perceptron 예제\n",
        "### nn.Sequential은 두 개의 레이어가 순차적으로 실행되게 하는 함수이다.\n",
        "* 아래 예제에서 input_data는 처음 perceptron nn.Linear(3,8)을 통과한 후 [5,12,8]의 사이즈를 가지게 된다.\n",
        "* 바로 다음 두번째 perceptron nn.Linear(8,16)을 통과한 후에는 [5,12,16]의 사이즈를 가지게 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVKqcK6oznKA",
        "outputId": "c48210c4-05d3-45fc-f0c0-33943bf23aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 16])\n"
          ]
        }
      ],
      "source": [
        "# nn.Sequential 예제\n",
        "\n",
        "two_layer = nn.Sequential(nn.Linear(3,8),\n",
        "                          nn.Linear(8,16)).to(device)\n",
        "input_data = torch.randn(5,12,3).to(device) # 12 X 3 행렬이 독립적으로 5개 있음을 의미함\n",
        "out = two_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 16]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8GRA24a3HBN"
      },
      "source": [
        "## Activation Function\n",
        "### activation function은 neural network의 layer를 통과한 후 output data 변형을 주는 함수이다.\n",
        "* 일반적으로 neural network의 layer는 linear이기 때문에 activation function로는 non-linear 함수를 많이 사용한다.\n",
        "* 이를 통해 neural network가 단일 linear function으로 귀결되는 것을 방지하고, 결과적으로 성능향상을 이끌 수 있다.\n",
        "\n",
        "### 대표적인 activation function (nn 모듈을 이용하여 사용가능)\n",
        "* Sigmoid (시그모이드)\n",
        "* ReLU (렐루)\n",
        "* tanh (하이퍼볼릭 탄제트)\n",
        "* 각 함수의 수식은 각자 검색하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m3OmtGY3HRz",
        "outputId": "f5a493d9-6da4-47ca-8da8-200ff60526ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인풋데이터 확인\n",
            "tensor([[[ 0.3607, -0.2859, -0.3938],\n",
            "         [ 0.2429, -1.3833, -2.3134],\n",
            "         [-0.3172, -0.8660,  1.7482],\n",
            "         [-0.2759, -0.9755,  0.4790],\n",
            "         [-2.3652, -0.8047,  0.6587]]])\n",
            "시그모이드 아웃풋\n",
            "tensor([[[0.5892, 0.4290, 0.4028],\n",
            "         [0.5604, 0.2005, 0.0900],\n",
            "         [0.4214, 0.2961, 0.8517],\n",
            "         [0.4315, 0.2738, 0.6175],\n",
            "         [0.0859, 0.3090, 0.6590]]])\n",
            "렐루 아웃풋\n",
            "tensor([[[0.3607, 0.0000, 0.0000],\n",
            "         [0.2429, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 1.7482],\n",
            "         [0.0000, 0.0000, 0.4790],\n",
            "         [0.0000, 0.0000, 0.6587]]])\n",
            "하이퍼볼릭 탄젠트 아웃풋\n",
            "tensor([[[ 0.3458, -0.2784, -0.3746],\n",
            "         [ 0.2383, -0.8817, -0.9806],\n",
            "         [-0.3070, -0.6994,  0.9412],\n",
            "         [-0.2691, -0.7511,  0.4454],\n",
            "         [-0.9825, -0.6666,  0.5775]]])\n"
          ]
        }
      ],
      "source": [
        "# activation function 예제\n",
        "sigmoid = nn.Sigmoid()\n",
        "relu = nn.ReLU()\n",
        "tanh = nn.Tanh()\n",
        "\n",
        "torch.random.manual_seed(100) # 랜덤시드 고정\n",
        "input_data = torch.randn(1,5,3)\n",
        "\n",
        "print('인풋데이터 확인')\n",
        "print(input_data)\n",
        "\n",
        "sigmoid_output = sigmoid(input_data)\n",
        "relu_output = relu(input_data)\n",
        "tanh_output = tanh(input_data)\n",
        "\n",
        "print('시그모이드 아웃풋')\n",
        "print(sigmoid_output)\n",
        "\n",
        "print('렐루 아웃풋')\n",
        "print(relu_output)\n",
        "\n",
        "print('하이퍼볼릭 탄젠트 아웃풋')\n",
        "print(tanh_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hOb4jne8I5d",
        "outputId": "02547160-41f8-43df-e298-f0ef895e053e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 16])\n"
          ]
        }
      ],
      "source": [
        "# nn.Linear + nn.Sequential + activation function 종합 예제\n",
        "my_model = nn.Sequential(nn.Linear(3,8),\n",
        "                         nn.Sigmoid(),\n",
        "                         nn.Linear(8,16),\n",
        "                         nn.ReLU()).to(device)\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = my_model(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 16]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8sI-sQC0mJC"
      },
      "source": [
        "## ★ 문제1\n",
        "### nn.Linear와 nn.Sequential을 사용하여 Five-Layer Perceptron을 구현하시오.\n",
        "#### 조건\n",
        "* input data 행렬의 row는 12, column은 3이다.\n",
        "* output 행렬의 column은 7이다.\n",
        "* 각 중간 layer의 out_features는 다음 순서를 따른다: [12,14,15,10,7]\n",
        "* activation function은 추가하지 않는다.\n",
        "* five_layer 모델은 GPU에서 실행되게 선언해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5N0rbCni0LWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9f0b82-5565-4c38-d6c6-75638ccb06bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 7])\n"
          ]
        }
      ],
      "source": [
        "five_layer = None\n",
        "######################## TODO ########################\n",
        "five_layer = nn.Sequential(nn.Linear(3,12),\n",
        "                            nn.Linear(12,14),\n",
        "                            nn.Linear(14,15),\n",
        "                            nn.Linear(15,10),\n",
        "                            nn.Linear(10,7)).to(device)\n",
        "\n",
        "######################################################\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = five_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # [5, 12, 7]이 출력되어야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4qRlNaqKIsM"
      },
      "source": [
        "##  ★ 문제2\n",
        "### nn.Linear, nn.Sequential, activation function을 사용하여 Ten-Layer Perceptron을 구현하시오.\n",
        "\n",
        "#### 조건\n",
        "* activation은 Sigmoid, ReLU, tanh 중 하나를 사용한다.\n",
        "* input data 행렬의 row는 12, column은 3이다.\n",
        "* output 행렬의 column은 아래 조건을 참고하여 알맞게 나오도록 한다.\n",
        "* 각 중간 layer의 out_features는 초항이 5, 공차가 2인 등차수열을 따른다. (즉, [5,7,9,...])\n",
        "* ten_layer 모델은 GPU에서 실행되게 선언해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4RFDC0nqKIUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6d8493-ca05-45db-98ca-ee0b1aa061b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 23])\n"
          ]
        }
      ],
      "source": [
        "ten_layer = None\n",
        "######################## TODO ########################\n",
        "ten_layer = nn.Sequential(nn.Linear(3,5), nn.ReLU(), nn.Linear(5,7), nn.ReLU(), nn.Linear(7,9), nn.ReLU(), nn.Linear(9,11), nn.ReLU(),\n",
        "                          nn.Linear(11,13), nn.ReLU(), nn.Linear(13,15), nn.ReLU(), nn.Linear(15,17), nn.ReLU(), nn.Linear(17,19), nn.ReLU(),\n",
        "                          nn.Linear(19,21), nn.ReLU(), nn.Linear(21,23), nn.ReLU()).to(device)\n",
        "######################################################\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = ten_layer(input_data)\n",
        "print(f'output 사이즈: {out.size()}') # 위 조건에 알맞은 사이즈가 출력되어야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzIiF9VudYEP"
      },
      "source": [
        "## nn.Module 클래스 사용\n",
        "### PyTorch의 장점은 nn.Moudule 클래스를 상속 받아서 사용자가 원하는 neural network를 구성할 수 있다는 점이다.\n",
        "\n",
        "### class 함수 설명\n",
        "* \\_\\_init\\_\\_: 클래스의 인스턴스를 생성할 때 가장 먼저 수행되는 부분. neural network에서 사용할 layer 또는 activation function 등을 정의한다.\n",
        "* forward: 실제로 neural network의 작동을 제어하는 함수. input data를 받은 후 neural network의 각 layer별 실행 순서를 정하고, 최종 output을 return한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ynaMgPGaLfT",
        "outputId": "72113507-9b7e-45d4-987c-7953efdd45b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output 사이즈: torch.Size([5, 12, 20])\n"
          ]
        }
      ],
      "source": [
        "# nn.Module 클래스 예시\n",
        "\n",
        "class MyMLP(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyMLP, self).__init__()\n",
        "    layers = [nn.Linear(3,8),\n",
        "              nn.Sigmoid(),\n",
        "              nn.Linear(8,20),\n",
        "              nn.ReLU()]\n",
        "    self.mlp = nn.Sequential(*layers) # 이러한 방식으로도 정의할 수 있다.\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.mlp(x)\n",
        "    return x\n",
        "\n",
        "my_model = MyMLP().to(device)\n",
        "input_data = torch.randn(5,12,3).to(device)\n",
        "out = my_model(input_data)\n",
        "print(f'output 사이즈: {out.size()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQZTbtZqe3ai"
      },
      "source": [
        "## ★ 문제3\n",
        "### 아래 조건에 맞게 nn.Module을 상속받는 클래스를 정의하시오.\n",
        "\n",
        "#### 조건\n",
        "* MLP (Multi-Layer Perceptron)의 layer는 nn.Linear만 사용한다.\n",
        "* \\_\\_init\\_\\_ 함수의 parameter 중 num_layers는 MLP의 layer의 개수를 의미한다.\n",
        "* \\_\\_init\\_\\_ 함수의 parameter 중 out_feat_list는 순서대로 MLP의 layer들의 out_features를 원소로 가지고 있다. out_feat_list의 길이는 num_layers와 항상 동일해야만 한다. (assert문 참고)\n",
        "* \\_\\_init\\_\\_ 함수의 parameter 중 act는 activation function을 의미한다. MLP의 모든 layer 뒤에는 항상 해당 activation function이 위치해야 한다. 문자열(string)으로 입력되며 'sigmoid', 'relu', 'tanh'만  입력되도록 한다. (assert문 참고)\n",
        "* input_data 행렬의 column은 1024로 가정한다. (Hint: 이는 MLP의 첫번째 nn.LInear layer의 input_features과 동일하다.)\n",
        "* 입력 및 모델 구조 출력 예시를 참고한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "r-0TP5iye3rR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db86bc22-5602-47c9-94b0-7c6252fca1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomMLP(\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=6, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
            "    (5): Sigmoid()\n",
            "    (6): Linear(in_features=3, out_features=4, bias=True)\n",
            "    (7): Sigmoid()\n",
            "    (8): Linear(in_features=4, out_features=9, bias=True)\n",
            "    (9): Sigmoid()\n",
            "    (10): Linear(in_features=9, out_features=10, bias=True)\n",
            "    (11): Sigmoid()\n",
            "    (12): Linear(in_features=10, out_features=2, bias=True)\n",
            "    (13): Sigmoid()\n",
            "    (14): Linear(in_features=2, out_features=4, bias=True)\n",
            "    (15): Sigmoid()\n",
            "  )\n",
            ")\n",
            "CustomMLP(\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=5, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=5, out_features=8, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=8, out_features=13, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=13, out_features=6, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Linear(in_features=4, out_features=9, bias=True)\n",
            "    (11): ReLU()\n",
            "    (12): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (13): ReLU()\n",
            "    (14): Linear(in_features=9, out_features=2, bias=True)\n",
            "    (15): ReLU()\n",
            "    (16): Linear(in_features=2, out_features=6, bias=True)\n",
            "    (17): ReLU()\n",
            "    (18): Linear(in_features=6, out_features=3, bias=True)\n",
            "    (19): ReLU()\n",
            "    (20): Linear(in_features=3, out_features=9, bias=True)\n",
            "    (21): ReLU()\n",
            "    (22): Linear(in_features=9, out_features=10, bias=True)\n",
            "    (23): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n출력결과\\nCustomMLP(\\n  (mlp): Sequential(\\n    (0): Linear(in_features=1024, out_features=5, bias=True)\\n    (1): ReLU()\\n    (2): Linear(in_features=5, out_features=8, bias=True)\\n    (3): ReLU()\\n    (4): Linear(in_features=8, out_features=13, bias=True)\\n    (5): ReLU()\\n    (6): Linear(in_features=13, out_features=6, bias=True)\\n    (7): ReLU()\\n    (8): Linear(in_features=6, out_features=4, bias=True)\\n    (9): ReLU()\\n    (10): Linear(in_features=4, out_features=9, bias=True)\\n    (11): ReLU()\\n    (12): Linear(in_features=9, out_features=9, bias=True)\\n    (13): ReLU()\\n    (14): Linear(in_features=9, out_features=2, bias=True)\\n    (15): ReLU()\\n    (16): Linear(in_features=2, out_features=6, bias=True)\\n    (17): ReLU()\\n    (18): Linear(in_features=6, out_features=3, bias=True)\\n    (19): ReLU()\\n    (20): Linear(in_features=3, out_features=9, bias=True)\\n    (21): ReLU()\\n    (22): Linear(in_features=9, out_features=10, bias=True)\\n    (23): ReLU()\\n  )\\n)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "class CustomMLP(nn.Module):\n",
        "  def __init__(self, num_layers: int, out_feat_list: List[int], act: str):\n",
        "    assert len(out_feat_list)==num_layers, 'out_feat_list size should be equal to num_layers'\n",
        "    super(CustomMLP, self).__init__()\n",
        "    activation = self.select_act(act)\n",
        "    layers = list()\n",
        "    ######################## TODO ########################\n",
        "    # (linear transformation + activation function / 총 두 개) * num_layers 만큼 리스트에 원소 미리 추가\n",
        "    for _ in range(num_layers*2):\n",
        "      layers.append(0)\n",
        "    # input_data 행렬의 column은 1024이므로, 첫번째 레이어는 직접 추가\n",
        "    layers[0] = nn.Linear(1024, out_feat_list[0])\n",
        "    layers[1] = activation\n",
        "    # for 문을 통해서 반복적으로 linear transformation + activation function 순으로 추가한다.\n",
        "    for i in range(1, num_layers):\n",
        "      layers[2*i] = nn.Linear(out_feat_list[i-1], out_feat_list[i])\n",
        "      layers[2*i+1] = activation\n",
        "    ######################################################\n",
        "    self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.mlp(x)\n",
        "    return x\n",
        "\n",
        "  def select_act(self, act: str):\n",
        "    assert act in ['sigmoid', 'relu', 'tanh', 'leakyrelu'], 'activation should be in [sigmoid, relu, tanh]'\n",
        "    if act == 'sigmoid':\n",
        "      return nn.Sigmoid()\n",
        "    elif act == 'relu':\n",
        "      return nn.ReLU()\n",
        "    elif act == 'leakyrelu': # add new activation function 'leaky relu'\n",
        "      return nn.LeakyReLU()\n",
        "    else:\n",
        "      return nn.Tanh()\n",
        "\n",
        "model = CustomMLP(num_layers=8, out_feat_list=[6,8,3,4,9,10,2,4], act='sigmoid')\n",
        "print(model)\n",
        "'''\n",
        "출력결과\n",
        "CustomMLP(\n",
        "  (mlp): Sequential(\n",
        "    (0): Linear(in_features=1024, out_features=6, bias=True)\n",
        "    (1): Sigmoid()\n",
        "    (2): Linear(in_features=6, out_features=8, bias=True)\n",
        "    (3): Sigmoid()\n",
        "    (4): Linear(in_features=8, out_features=3, bias=True)\n",
        "    (5): Sigmoid()\n",
        "    (6): Linear(in_features=3, out_features=4, bias=True)\n",
        "    (7): Sigmoid()\n",
        "    (8): Linear(in_features=4, out_features=9, bias=True)\n",
        "    (9): Sigmoid()\n",
        "    (10): Linear(in_features=9, out_features=10, bias=True)\n",
        "    (11): Sigmoid()\n",
        "    (12): Linear(in_features=10, out_features=2, bias=True)\n",
        "    (13): Sigmoid()\n",
        "    (14): Linear(in_features=2, out_features=4, bias=True)\n",
        "    (15): Sigmoid()\n",
        "  )\n",
        ")\n",
        "'''\n",
        "\n",
        "model = CustomMLP(num_layers=12, out_feat_list=[5,8,13,6,4,9,9,2,6,3,9,10], act='relu')\n",
        "print(model)\n",
        "'''\n",
        "출력결과\n",
        "CustomMLP(\n",
        "  (mlp): Sequential(\n",
        "    (0): Linear(in_features=1024, out_features=5, bias=True)\n",
        "    (1): ReLU()\n",
        "    (2): Linear(in_features=5, out_features=8, bias=True)\n",
        "    (3): ReLU()\n",
        "    (4): Linear(in_features=8, out_features=13, bias=True)\n",
        "    (5): ReLU()\n",
        "    (6): Linear(in_features=13, out_features=6, bias=True)\n",
        "    (7): ReLU()\n",
        "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
        "    (9): ReLU()\n",
        "    (10): Linear(in_features=4, out_features=9, bias=True)\n",
        "    (11): ReLU()\n",
        "    (12): Linear(in_features=9, out_features=9, bias=True)\n",
        "    (13): ReLU()\n",
        "    (14): Linear(in_features=9, out_features=2, bias=True)\n",
        "    (15): ReLU()\n",
        "    (16): Linear(in_features=2, out_features=6, bias=True)\n",
        "    (17): ReLU()\n",
        "    (18): Linear(in_features=6, out_features=3, bias=True)\n",
        "    (19): ReLU()\n",
        "    (20): Linear(in_features=3, out_features=9, bias=True)\n",
        "    (21): ReLU()\n",
        "    (22): Linear(in_features=9, out_features=10, bias=True)\n",
        "    (23): ReLU()\n",
        "  )\n",
        ")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEM9XM-c7yL5"
      },
      "source": [
        "---\n",
        "# ※ Section II. MLP를 이용한 이미지 분류 예측 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKYBqeAHOcPb"
      },
      "source": [
        "## CIFAR10 데이터\n",
        "* train: 50,000장\n",
        "* test: 10,000장\n",
        "* label: 10개 (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPGIRI5kPMeE",
        "outputId": "0f421408-7b2a-4e40-a9b7-ef4501100a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 사용 희망 시 아래 코드 주석 해제하고 실행\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dZg9cAfWPGWG"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import functional as TF\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygQxBQkLnNCt"
      },
      "source": [
        "## 데이터 저장\n",
        "### 코랩 임시 저장소 또는 구글 드라이브에 데이터 저장\n",
        "* 둘 중 원하는 방법 선택하여 실행\n",
        "* 참고: 데이터 사이즈 약 350MB\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3pJ-j4Slj5O",
        "outputId": "0718c1bf-8d8b-47bc-c38b-1f5b8bca9d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# 임시 저장소에 저장 / 코랩 런타임 끊길 경우 초기화\n",
        "# traindata = datasets.CIFAR10(root = './data', train = True, download = True)\n",
        "# testdata = datasets.CIFAR10(root = './data', train = False, download = True)\n",
        "\n",
        "# 구글 드라이브에 저장 / 코랩 런타임 끊기더라도 초기화 되지 않음\n",
        "trainset = datasets.CIFAR10(root = '/content/drive/MyDrive/data', train = True, download = True)\n",
        "testset = datasets.CIFAR10(root = '/content/drive/MyDrive/data', train = False, download = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIno48Ofnp6P"
      },
      "source": [
        "## 데이터 상세정보 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi1mezKinpYU",
        "outputId": "0b2bd70e-92d2-4e1e-f7ef-47092e09d80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000 10000\n"
          ]
        }
      ],
      "source": [
        "# data 사이즈 확인\n",
        "print(len(trainset), len(testset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "s_MqoHXymhNC",
        "outputId": "c9901a37-d94f-4ea9-816e-3a163b852151"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAw70lEQVR4nO3de5DU9Znv8U/fp+fWw8wwNxiQi+IVckIUJyauEVZgqzwaqS1NUrWYtfTojtYqm03CVqLR3a1xTZ3EJEXwj3VlUxU0cSvo0droKgaobMANRAovCRGCAsIM17n19L1/5w/X2YyCfB+c4cuM71dVV8nM4zPf36X7md9096dDQRAEAgDgDAv7XgAA4OOJAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8CLqewHvVy6XdeDAAdXU1CgUCvleDgDAKAgCDQwMqK2tTeHwya9zzroBdODAAbW3t/teBgDgI9q3b5+mTp160u+P2QBatWqVvv3tb6u7u1vz5s3TD37wA1122WWn/P9qamokSfMvW6Bo1G15fX3HndeVCJedayVpUtw9qWjqpEpT78Z69/qGVJWpdzwcc66NJJKm3opETOXHe/ucawtFWzJUXSrlXBsuFUy9c/mcc202614rSRXJhKm+pJJzbSaTNvWuTdW4Fwfu65CkfN59n0eMD0cRw3lYXVVt6l1VabsvR2MVzrXZXN7UOwgZnikJ2/ZhPu++lmLg/hepbC6vb37/x8OP5yczJgPoJz/5iVasWKFHHnlECxYs0MMPP6zFixdr586dampq+tD/970/u0WjUecBZDkRI2Hbn/WiEfcHxHjM9sCciLnv/oq4+0CRpHjEvT6asPVWxHbaZAxrD4dtA6jCsPaw7bFTIRl+WSnbmluPZ8nwdG25ZDs+ln2owPa0cVjuxzMi2z6x3O+TxnM8WRE31cdi7vXWZxbGcgBFDGuxDKD3nOpplDF5EcJ3vvMd3Xrrrfryl7+sCy+8UI888ogqKyv1L//yL2Px4wAA49CoD6B8Pq9t27Zp0aJF//NDwmEtWrRImzdv/kB9LpdTf3//iBsAYOIb9QF05MgRlUolNTc3j/h6c3Ozuru7P1Df1dWlVCo1fOMFCADw8eD9fUArV65UX1/f8G3fvn2+lwQAOANG/UUIjY2NikQi6unpGfH1np4etbS0fKA+kUgokbC9IggAMP6N+hVQPB7X/PnztX79+uGvlctlrV+/Xh0dHaP94wAA49SYvAx7xYoVWr58uT71qU/psssu08MPP6x0Oq0vf/nLY/HjAADj0JgMoBtvvFGHDx/Wvffeq+7ubn3iE5/Qc88994EXJgAAPr5CQRDY3vk3xvr7+999RVx9vUIfkiH0x3qPHHHuX+/+hmVJ0owG9//h3BbDO8olnTP9w9+U+8cqEra/lgYl98MahGxvuhvK2t7JPZRxTwkolGxJFVHDO+kqorZTvVh0X0vE+AZA6/OeQ1n3dINi2XZ8GhsbnGvDtvdaq5BzP/bJqO3OmTMkCpRKRVPvykpb8kjIkDwSMrxJXJLk+DgoSUNZW9pHsWBIqoi6n7O5QlH/92e/Vl9fn2pra09a5/1VcACAjycGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwIsxyYIbDRXRkMJhx5gVQ6rJdEO0jiSd05xyrm2aXG/qnTTEfZzqs9XfL5PLOtdmC+5xKZIUGNcSTybdi4u2uJyg7L72VH2lqXex4L6WeMywjZJKJVO5InFDDEre/dhLUqHofjwrDeuQpGiV+36pMPYuhtzjicKBLeKpKNs5bkiEUnWV7TwcTA851xaKtige14dYSRro73OuzRfcTnCugAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABenL1ZcKGSwiG3/KaaGvfNOG/KJNM6GpIR59pY2ZbBNXgs71xbKtt+V8gMFZ1rw3FTa9XWVZvqo4aMr96+AVtvwxlcX2PL4Brod88ay2fdayUpk7VldgWGbLLqKveMQUkq5DPOteGS7SEjlnA/9qWSbZ9EDQFsuZytdzxmu1OEy+73t9zgcVNvldwzCRPuD1eSpGLZPSOvL+2eu5gvuvXlCggA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MVZG8VTl4goEnabj0lD3EeqKmlax+TamHNtqVwy9bZUR6LGjA3HfSdJubIxAsWSfyMpGrjHfZRy7rEwkhRE3Lfz0KFeU+9Swf0IDQwNmXoPldxjmCSpOlnrXpyznYcRuR+fcMg9FkaSIokK59pM2hZlVRlz3yfRwLbubNZ2fDIF9yiesmxr6R103y+9Q7b78qAhsitbcL+vFUtE8QAAzmIMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF2dtFlxjqkJRx5yvmph7TlpFhS1TLRxxz21KJm05c4Wie2ZXWSFT7yBwz7LKF23ZVKW8LW+qHLjXB8aMtCAad64dyKdNvUsl93NlyDH76j2uWVnvGUi778N3jtm2MxZ2X0vtoO08LHQfca7N9Nny9KY1znaubWqaauodqukz1eeOH3WuHRy0HZ++AfcsuCN9tizFt/a5b2cp4j4uyo7Ze1wBAQC8GPUB9K1vfUuhUGjE7fzzzx/tHwMAGOfG5E9wF110kV588cX/+SHG+H4AwMQ3JpMhGo2qpaVlLFoDACaIMXkO6M0331RbW5tmzpypL33pS9q7d+9Ja3O5nPr7+0fcAAAT36gPoAULFmjNmjV67rnntHr1au3Zs0ef/exnNTAwcML6rq4upVKp4Vt7e/toLwkAcBYa9QG0dOlS/fmf/7nmzp2rxYsX69///d/V29urn/70pyesX7lypfr6+oZv+/btG+0lAQDOQmP+6oC6ujqdd9552rVr1wm/n0gklEgkxnoZAICzzJi/D2hwcFC7d+9Wa2vrWP8oAMA4MuoD6Ctf+Yo2btyot956S7/61a/0+c9/XpFIRF/4whdG+0cBAMaxUf8T3P79+/WFL3xBR48e1eTJk/WZz3xGW7Zs0eTJk019WhorFY+6RaHUxovOfasr3aNbJClkiJGRbJE2ocA9AiWXscWUhA3RPQ01KVPvqqoKU31/n3scS6q21tR7IOt+fN5+x30dkjSYc4/iiduSdTSl0nbXi8bcI1beOtpr6p0L3LczFrKd46naGufaT1/4KVPv/oPuUVbBkHHdjTFTfW7I/XgODtp+70/E3NfS3uK+vyWpqanZuban3z0SqFgqa+9r+09ZN+oD6IknnhjtlgCACYgsOACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF2P+cQyna1J1UomYW0ZVNN/r3DcRs21yZaLSuTaXseTGSYWye4ZdXd0kU+8gcM++ypdsv4cUCu6ZUJJUWV3tXHvgcM7Ue/fbfc61hwfc97ckDRnKpyfd89Qk6frPfsJUP7XVfR/+27Y/mHpv3tXtXFss5029o2H383Cg97Cp99Cg+7lSU2PLdlPJPUtRkioq3PvHK2znSmXIvXexZDvHp7W3OdfWHDvxh4qeSL5Q0iaHLDiugAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXpy1UTyTJ9WrIu62vMwx92iYcMi2yYND7vE6mbwtBiMaco/kGCqUTL0tv1lkCrZ4lbpJtab6fMk9juUP+w+Yeh/rd98vQTRu6h2JuO/F2grb8WmKuseaSFLFMffYmXNrW0y9D9a7b2dP7yFT79yQ+7n1yu9/b+odLpadawtVtnNWqWZbfdj9cSWVco/3kqSasvv9J5u3xYEF+X7n2nMmVxnW4fZYyBUQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwIuzNguurqFRyUTMqXZSddK5bzjs1vM9vf3HnWsL6UFT73DJPT+sLPfcK0kKYu6Htrq6wtS7IFv9b//gnvGVzqVNvSsqEu61jtmC70lWuWd2TYrYcgC37eox1Rfz7mvPpWxZcJMnuR/PkGyZaoWie07jUD5j6p0ecs9IyxdtxydkzEdUyL00FjYUSwrC7pmRsajtHC/m3DMGA0Omo2stV0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL87aLDiFo5JjblsoZst3s0hUuPeuVJWpd9Qw/8Nh2+8KBUN2XCKZMvU+0j1gqh864p6nN7PeljOXc48aU4Uh202S5sya4lwbtixEUjFiO2f7DZmE0UifqXdN3P28bZg0y9R71rnTnGv37P21qffvfv+Oc2086p55JklBYMt1LBbdH0rD0bipdyzufq6Uy7bMyLIhxC4Ucn8Mcq3lCggA4IV5AG3atEnXXnut2traFAqF9NRTT434fhAEuvfee9Xa2qpkMqlFixbpzTffHK31AgAmCPMASqfTmjdvnlatWnXC7z/00EP6/ve/r0ceeUQvv/yyqqqqtHjxYmWztj9RAAAmNvNzQEuXLtXSpUtP+L0gCPTwww/rG9/4hq677jpJ0o9+9CM1Nzfrqaee0k033fTRVgsAmDBG9TmgPXv2qLu7W4sWLRr+WiqV0oIFC7R58+YT/j+5XE79/f0jbgCAiW9UB1B3d7ckqbm5ecTXm5ubh7/3fl1dXUqlUsO39vb20VwSAOAs5f1VcCtXrlRfX9/wbd++fb6XBAA4A0Z1ALW0vPtZ9D09Iz/vvqenZ/h775dIJFRbWzviBgCY+EZ1AM2YMUMtLS1av3798Nf6+/v18ssvq6OjYzR/FABgnDO/Cm5wcFC7du0a/veePXu0fft21dfXa9q0abr77rv1D//wDzr33HM1Y8YMffOb31RbW5uuv/760Vw3AGCcMw+grVu36nOf+9zwv1esWCFJWr58udasWaOvfvWrSqfTuu2229Tb26vPfOYzeu6551RRYYtYyWaLUuAWExEqZAydi6Z1pNPur8rLF2wXlMWw+z4ZHLLF3/Qb6qe0206DoGhby/RG97iPWW22iJqhrHvvKefNM/WOB+7vXTveVzD1TtY1mOp1NOJc2t7Samrdm0471848/1xT79pJ7vFHtZMuMPU+ftj9PDzeZ4snihniiSQpHCScawvlkqm3JV2nVLA9voXd7z4KgmDUa80D6KqrrvrQ5qFQSA888IAeeOABa2sAwMeI91fBAQA+nhhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL8xRPGdKKVRSKeQ2H4OSe/6RJc9IkpIVSefa6hr33CtJOnDYPcNuz/7Dpt7RmPt2xnsOmHpne2xrObfJPd9t4VW2rLHd7xxzrq2ZMtnUu7HhxB8hciKHDvecuuiP1NUZs8bK7vswHnbPjZOkQ4ffca6NVvSaeh/uPehc+87BQVPvWMz9/lZXawhUk5TJ2B4ngqj77/IhSwCbpLIhOy4csvUOhd3XXbLtEidcAQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvDhro3hSqSolK+JOtcWoexTP4GDWtI6g4B6D0TfQZ+r99l73+JbBQVtMSbLC/XeLg3v6Tb2bHY/Le6ZMme5cW9c2w9Q7NmCIWKlwj7ORpKnzLnNv3e0eZyNJyaItzqgk9/M2nbad462V7hFF+ZIt0iZUVe1cO7WqzdS7ps49KmngaLep96Geo6b6Qsj93Mrmc6beCrtn4FQlKkyt8xn3x5VY3H0bS3KLBOIKCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODFWZsFN9h3TMWsW/ZQND/g3DcWMs7ciHtpNGIoljQ06J4dN6mmytS7rso9Eypz3JYF19TWYKqfMvdPnGtf25839f79Lvf6T7fWm3r39rr3bp41z9Q7rCFTfT7nnh1XF9jy2voPueeeJfMFU+/Wevd93ltKmHrH5k5yrs30HjT1/s9//3+m+v373I9PxJCp9i63XDVJyrjHxkmSCoZrkHDB/dhnC275nFwBAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8OGujeMIhKeKYQFHKDDr3DQyxFpIUllukhCSVQrYonuOGVJP+flvGRpBzj5FpTdlifi793OdM9VPnXO5c+7PH/sXUu6Wq2rk2ks+Yer/zh93u65h5oal3RcNsU31V4B43NXTskKl3suweaZPP2CKEjgy419dNnmHq3dByjnNtZrDW1DtsK1cpnnWuDYVtj0GFgvt9OVQsmXqHAvf6YtF9XBRKbo9XXAEBALxgAAEAvDAPoE2bNunaa69VW1ubQqGQnnrqqRHfv/nmmxUKhUbclixZMlrrBQBMEOYBlE6nNW/ePK1ateqkNUuWLNHBgweHb48//vhHWiQAYOIxvwhh6dKlWrp06YfWJBIJtbS0nPaiAAAT35g8B7RhwwY1NTVpzpw5uuOOO3T06Mk/8CqXy6m/v3/EDQAw8Y36AFqyZIl+9KMfaf369fqnf/onbdy4UUuXLlWpdOKX+3V1dSmVSg3f2tvbR3tJAICz0Ki/D+imm24a/u9LLrlEc+fO1axZs7RhwwYtXLjwA/UrV67UihUrhv/d39/PEAKAj4Exfxn2zJkz1djYqF27dp3w+4lEQrW1tSNuAICJb8wH0P79+3X06FG1traO9Y8CAIwj5j/BDQ4Ojria2bNnj7Zv3676+nrV19fr/vvv17Jly9TS0qLdu3frq1/9qmbPnq3FixeP6sIBAOObeQBt3bpVn/ujLLD3nr9Zvny5Vq9erR07duhf//Vf1dvbq7a2Nl1zzTX6+7//eyUSCdPPCQXv3lyUCu6haqGw7aIvaigPMoZwN0mhsnttfUOlqXdLpXuG3Sc/dZ6p9wWfds92k6Tjh9yz+hLFPlPvmVOnOteWLTtcUkvTZOfaYtZ9f0vSUK97vpck5Yvu/QsZ2926JPc8vd3v7Df1fvW1rc61n77ctk8aWhqca/sHbPl4MdvdTY3nuOcplo2PQaW8Ia/NkAEpSX2He51rcwPuOyVXcFuzeQBdddVVCoKTT4bnn3/e2hIA8DFEFhwAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwItR/zyg0VIullSOuM3HTM494yte5Z57JUnRaMy5NhK25TDNbpnkXFuRtP2ucM50989UmveZz5266I+0zplrqt+++THn2mnt7vtEklouusS5Nj55lql3tDLlXDuUdc+7k6RM/4CpvufAPufa4z22vLZSYci5NllTYerd2Oh+/9l34BVT7+bWKc61xSHb8QkyOVN9KH3cubYUZGxrcQ3FlJRMuO9vSYq3uNf3J0LOtdm8Wy1XQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL87aKJ5YJKpYxG15xwfco0RKWfc4CUlKViadayNh98gMSWpqqHSu3Xew19R71ieXONdOvcS99l22uJzCQNq5NlXjHn8jSZPP+4RzbTpab+r9+iu/dq7NZdy3UZL6+3tN9Ufe2etcGynZIqEqKtwfBqbMcI+/kaS55812ri1Gqky9Y5E699p4wdQ7ms2a6ofefse5tlwsmXoXDZcJg5GIqXdlg/s+b25rcK7NZN22kSsgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBdnbRZcPptTuOyWJ1SZcN+MUIUtKykWLjrXBiX3WklKVruv5X/f+L9NvT+9dKFzbW1js6l3zx9+a6qPGPZh70Cfqffht3Y61x4YsGVwbXjqKefa6mTM1DubGzTVtzS7Z+TV1tgy1fbs3+dcmzccS0mqbzvHufa8S+abequUcC491rvf1HrImBl5POO+X0KB7WE3myk71w4GtjzKYNA98+6COve+Wcc4Qq6AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABenLVRPOUgr3LgGEHhGNkjSaGie6yFJBWDgnvvkC0GoyJR61z7ifm2mJJEzD0a5o3tr5h6Hz+w21Sfy7nHfQwcP2bqvW/XG861g0HS1DtWcl93ddQW8VRbYYvLmTzJPYrnYE+3qXex4H6ODw3YIoT27dlrqH7d1HtwcMC5tiJqu28WE02m+qNF9/tyMllh6l1Z437eJqPu8USSNDDU71xbLLvHDRUdH5O5AgIAeGEaQF1dXbr00ktVU1OjpqYmXX/99dq5c2QYZDabVWdnpxoaGlRdXa1ly5app6dnVBcNABj/TANo48aN6uzs1JYtW/TCCy+oUCjommuuUTqdHq6555579Mwzz+jJJ5/Uxo0bdeDAAd1www2jvnAAwPhmeg7oueeeG/HvNWvWqKmpSdu2bdOVV16pvr4+Pfroo1q7dq2uvvpqSdJjjz2mCy64QFu2bNHll18+eisHAIxrH+k5oL6+dz+7pb6+XpK0bds2FQoFLVq0aLjm/PPP17Rp07R58+YT9sjlcurv7x9xAwBMfKc9gMrlsu6++25dccUVuvjiiyVJ3d3disfjqqurG1Hb3Nys7u4TvzKnq6tLqVRq+Nbe3n66SwIAjCOnPYA6Ozv12muv6YknnvhIC1i5cqX6+vqGb/v2uX86IwBg/Dqt9wHdeeedevbZZ7Vp0yZNnTp1+OstLS3K5/Pq7e0dcRXU09OjlpaWE/ZKJBJKJGyvXQcAjH+mK6AgCHTnnXdq3bp1eumllzRjxowR358/f75isZjWr18//LWdO3dq79696ujoGJ0VAwAmBNMVUGdnp9auXaunn35aNTU1w8/rpFIpJZNJpVIp3XLLLVqxYoXq6+tVW1uru+66Sx0dHbwCDgAwgmkArV69WpJ01VVXjfj6Y489pptvvlmS9N3vflfhcFjLli1TLpfT4sWL9cMf/nBUFgsAmDhCQRDYQpLGWH9/v1KplLr+8jOqiLvNx2P733LuH0/WmdZTKrrnZBXknpUkSdNmn+veO2TLMatvnnHqov/W1Gp75WF+qM9Unz60x733UUt2mDRtxjTn2kLMlr/2+1dfc67NDBw39U5W2p73DMXc/1qezuZMvQO559jlg5Cpd0jumYTVSfc8NUnKFTPuxTFbVl8pbKt/Z+AP7sVVeVPvyoT7dUJF2fa0flJx59oL5p7nXDuUKejG//P/1NfXp9rakx9XsuAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6c1scxnAnlckjlslvsRzzqHptRES3bFhJ2jx4JIraol3LePebnyJETf6DfyQwedq9PFmyfQls2RLdIUv2kBufaurbJpt7FknvszDsHbPswkHtKVThsuyvli7bYpkjIPdKmqqLS1LtouEtELMWSFHLfh6W8LeIp7Pj4IEn9Q7aopHzCEPMjqabN/TxMJ3tNvQfK7tE92bTtmqKhdqZzbWOT+/04nXZbM1dAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/O2iy4cCihcMhteRWJpHPfQLYMrqqke65WVU2jqfdQIetc21ATN/WOGrYz39dj6l0O29YyFHPPD2tunmFbS949J2vO3Kmm3r/6xXrn2nwwZOodC7nnmElSZtC9f21Nral3POr+MBAJ2bLgBrPu5/ieg7a8tt5e93M8F0qbek8+z/a7+ZQ698egfGC7/xw/4n7s41n3zEBJqprinu+WGSq512bcarkCAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4cdZG8cSiIcWjbvNxKJdz7hupqDKtoxxJONcOFTKm3pFY4FybiLtHfUhSLOa+nfHKlKl3qta2D7sPu0f9DE2xxeU0tc92rn3n0BFT74suvcK5dvDwAVPvP/z+dVN9erDXuTYasZ2HqZR7dE9Itiieg++475e9b/eZeocT7udhbbN7pJYkTa63xRmFDJFDoWO2+8+k4+4P01Oa6k29p9a53992vdHtXJvJFpzquAICAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeHHWZsE1NYRVWeE2HwtHjzr3zZRsWVbptHttEC6Zekej7ru/trbB1DseiznXZtL9pt7JmPG0ybvXb/3Vr0ytZ85xz5nbv989y0qSwuGQc21lwn1/S1LEkDEoScmke35YetCWBZfJuNcXi3lT7+qk+3Z++n+dZ+pdUeOe11aMFE29S4UhU31mn3sWXHigwtS7qbLGufZ/nXeRrXdds3PttoN7nGuzebf9zRUQAMAL0wDq6urSpZdeqpqaGjU1Nen666/Xzp07R9RcddVVCoVCI2633377qC4aADD+mQbQxo0b1dnZqS1btuiFF15QoVDQNddco/T7/k5166236uDBg8O3hx56aFQXDQAY/0x/zH/uuedG/HvNmjVqamrStm3bdOWVVw5/vbKyUi0tLaOzQgDAhPSRngPq63v3A6Tq60d+CNKPf/xjNTY26uKLL9bKlSs1NHTyJ/RyuZz6+/tH3AAAE99pvwquXC7r7rvv1hVXXKGLL754+Otf/OIXNX36dLW1tWnHjh362te+pp07d+pnP/vZCft0dXXp/vvvP91lAADGqdMeQJ2dnXrttdf0y1/+csTXb7vttuH/vuSSS9Ta2qqFCxdq9+7dmjVr1gf6rFy5UitWrBj+d39/v9rb2093WQCAceK0BtCdd96pZ599Vps2bdLUqR/+meILFiyQJO3ateuEAyiRSCiRsL0nAgAw/pkGUBAEuuuuu7Ru3Tpt2LBBM2bMOOX/s337dklSa2vraS0QADAxmQZQZ2en1q5dq6efflo1NTXq7n73neWpVErJZFK7d+/W2rVr9Wd/9mdqaGjQjh07dM899+jKK6/U3Llzx2QDAADjk2kArV69WtK7bzb9Y4899phuvvlmxeNxvfjii3r44YeVTqfV3t6uZcuW6Rvf+MaoLRgAMDGY/wT3Ydrb27Vx48aPtKD3TJ0aV3XSLV8rFXLPVtq1z5bx1HP4w7f5j+VLtueyqqvdd396qM/Uu1QedK6NGF+Nf+ywe/aeJA0MuudwZQu27YwE7vU11ZNMvXu6jznX7k+7Z4FJUjlwz5mTpObJ7lmAoXLB1Pt473Hn2kSV7RyvS7nnmMUjtvMwlzdkL0ZtWX3pnG0t+UH3/lVlW+/Z7e7vqWxrsWVG7tvvnqV49LD7Y2eu4HZsyIIDAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhx2p8HNNZq62KqrnSLt8gYIiImNUVsC6mqdC490pMztc7m88610XitqbehtcqOsRnvKZRs29mXcY96qUraol6yQ+4ROJnsEVPvvGG/lIz7MAhs5+Fgv/s5XlubNPWurU0512YytiirI0fdj311dZWpdyjs/vtzqOgeqSVJ8ahtHybc08AUj9uO/Tmzz3GuzQzZtnPTpjeca3f8/pBzbbFUdqrjCggA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxVmbBRepiCpa4ba8itq4c9/6atvMjWbcc89iSbf8o/f0Hzfs/pJt3cmKJvfWMdu6S7leU3280n07Y1H3YylJkYh7Vl8usG1nvuAeqBcEIVPvkC2yS0HePfOu5F4qSYpF3TIXJUlxW1Zf73H3LLhMvmDqnapzz0eMGnLjJClsPA+HVHSu7TkyYOp9fNC990C6z9T7xQ2/c67tMcQAlstuJzhXQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL87aKJ70YFShsmNESKTauW91lS2nJJZ0z0ypSlSYeqdS7tEwg/0ZU+/B/h732qGSqXcha6uviTc411bEDLEwkoo596ikaNT2+1bcUB5LREy9QyHbWiqr3e+qYeO9ulhyj3qJJ23Na+vco5KOHbNF1AwYopVq693PQUkaKrrHMEnSm28dda793av7TL2b690jh5qnuu9vSVLYfR82pmqca0vlst4+furHWq6AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6ctVlwB/ZJlY7Rarle9wy2msnuuVeSVJEsONem3CPpJEn19e67fzA9ZOrd2+tef/xo3NT7uHvslSQpUnbPSSsH7tl7klQqGXLpyrYMO8tvZ6FwyNQ7ErXd9TIl99UEtlNcsbL7OV4cOmbqXcq4n4elqC0HsHfQvXfeduh1zJi9+NYu9ztF79G0qXc+7b74llSLqfcF06c411p2SaFU1m/eOvW5whUQAMAL0wBavXq15s6dq9raWtXW1qqjo0M///nPh7+fzWbV2dmphoYGVVdXa9myZerpcU9lBgB8fJgG0NSpU/Xggw9q27Zt2rp1q66++mpdd911ev311yVJ99xzj5555hk9+eST2rhxow4cOKAbbrhhTBYOABjfTH+Ivvbaa0f8+x//8R+1evVqbdmyRVOnTtWjjz6qtWvX6uqrr5YkPfbYY7rgggu0ZcsWXX755aO3agDAuHfazwGVSiU98cQTSqfT6ujo0LZt21QoFLRo0aLhmvPPP1/Tpk3T5s2bT9onl8upv79/xA0AMPGZB9Crr76q6upqJRIJ3X777Vq3bp0uvPBCdXd3Kx6Pq66ubkR9c3Ozuru7T9qvq6tLqVRq+Nbe3m7eCADA+GMeQHPmzNH27dv18ssv64477tDy5cv1xhtvnPYCVq5cqb6+vuHbvn22j6sFAIxP5vcBxeNxzZ49W5I0f/58/frXv9b3vvc93Xjjjcrn8+rt7R1xFdTT06OWlpO/Nj2RSCiRSNhXDgAY1z7y+4DK5bJyuZzmz5+vWCym9evXD39v586d2rt3rzo6Oj7qjwEATDCmK6CVK1dq6dKlmjZtmgYGBrR27Vpt2LBBzz//vFKplG655RatWLFC9fX1qq2t1V133aWOjg5eAQcA+ADTADp06JD+4i/+QgcPHlQqldLcuXP1/PPP60//9E8lSd/97ncVDoe1bNky5XI5LV68WD/84Q9Pa2GlWINKMbc/zRXin3LumyvnTOsIF48411akbHEsdZPdI4QmhW35KvVDZefa3mNJU+/eI+7ROpKUSbufZqWiLRZIgftFfLnovk8kKZvJOtfG47Z1R6K2fTiQdV97ZtB93ZIUC/LOtTXhGlPvctj9Va2Fgu0ZgUSVe2xTheNjyXvq4u77RJJmqs659pJ5Vabec+bOc64957+fHnF12eXucUb7Dww61+byRek3b52yznTEH3300Q/9fkVFhVatWqVVq1ZZ2gIAPobIggMAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhhTsMea0HwbrzGUNY9CiNjqA3FCqb1lMvuETjhIVsUTzRtWEu4ZOqdzrhHt6Qztn0yZIiFkaRM1j0yxbC7/9sYRvHk3PdLKbAd+0jJdjwzOfd9mM3bjmcQuNdHjZFQ2bx7fc567EPu+yQS2KKPcgXbYvJF9+MZM/a2PBYOpm0xTBnDOZ6zHMv/3sb3Hs9PJhScquIM279/Px9KBwATwL59+zR16tSTfv+sG0DlclkHDhxQTU2NQqH/+a2yv79f7e3t2rdvn2praz2ucGyxnRPHx2EbJbZzohmN7QyCQAMDA2pra1M4fPK/Upx1f4ILh8MfOjFra2sn9MF/D9s5cXwctlFiOyeaj7qdqVTqlDW8CAEA4AUDCADgxbgZQIlEQvfdd58SCdsHS403bOfE8XHYRontnGjO5HaedS9CAAB8PIybKyAAwMTCAAIAeMEAAgB4wQACAHgxbgbQqlWrdM4556iiokILFizQf/3Xf/le0qj61re+pVAoNOJ2/vnn+17WR7Jp0yZde+21amtrUygU0lNPPTXi+0EQ6N5771Vra6uSyaQWLVqkN998089iP4JTbefNN9/8gWO7ZMkSP4s9TV1dXbr00ktVU1OjpqYmXX/99dq5c+eImmw2q87OTjU0NKi6ulrLli1TT0+PpxWfHpftvOqqqz5wPG+//XZPKz49q1ev1ty5c4ffbNrR0aGf//znw98/U8dyXAygn/zkJ1qxYoXuu+8+/eY3v9G8efO0ePFiHTp0yPfSRtVFF12kgwcPDt9++ctf+l7SR5JOpzVv3jytWrXqhN9/6KGH9P3vf1+PPPKIXn75ZVVVVWnx4sXKZm2Bir6dajslacmSJSOO7eOPP34GV/jRbdy4UZ2dndqyZYteeOEFFQoFXXPNNUqn08M199xzj5555hk9+eST2rhxow4cOKAbbrjB46rtXLZTkm699dYRx/Ohhx7ytOLTM3XqVD344IPatm2btm7dqquvvlrXXXedXn/9dUln8FgG48Bll10WdHZ2Dv+7VCoFbW1tQVdXl8dVja777rsvmDdvnu9ljBlJwbp164b/XS6Xg5aWluDb3/728Nd6e3uDRCIRPP744x5WODrev51BEATLly8PrrvuOi/rGSuHDh0KJAUbN24MguDdYxeLxYInn3xyuOa3v/1tICnYvHmzr2V+ZO/fziAIgj/5kz8J/vqv/9rfosbIpEmTgn/+538+o8fyrL8Cyufz2rZtmxYtWjT8tXA4rEWLFmnz5s0eVzb63nzzTbW1tWnmzJn60pe+pL179/pe0pjZs2ePuru7RxzXVCqlBQsWTLjjKkkbNmxQU1OT5syZozvuuENHjx71vaSPpK+vT5JUX18vSdq2bZsKhcKI43n++edr2rRp4/p4vn873/PjH/9YjY2Nuvjii7Vy5UoNDQ35WN6oKJVKeuKJJ5ROp9XR0XFGj+VZF0b6fkeOHFGpVFJzc/OIrzc3N+t3v/udp1WNvgULFmjNmjWaM2eODh48qPvvv1+f/exn9dprr6mmpsb38kZdd3e3JJ3wuL73vYliyZIluuGGGzRjxgzt3r1bf/d3f6elS5dq8+bNikRsn1NzNiiXy7r77rt1xRVX6OKLL5b07vGMx+Oqq6sbUTuej+eJtlOSvvjFL2r69Olqa2vTjh079LWvfU07d+7Uz372M4+rtXv11VfV0dGhbDar6upqrVu3ThdeeKG2b99+xo7lWT+APi6WLl06/N9z587VggULNH36dP30pz/VLbfc4nFl+Khuuumm4f++5JJLNHfuXM2aNUsbNmzQwoULPa7s9HR2duq1114b989RnsrJtvO2224b/u9LLrlEra2tWrhwoXbv3q1Zs2ad6WWetjlz5mj79u3q6+vTv/3bv2n58uXauHHjGV3DWf8nuMbGRkUikQ+8AqOnp0ctLS2eVjX26urqdN5552nXrl2+lzIm3jt2H7fjKkkzZ85UY2PjuDy2d955p5599ln94he/GPGxKS0tLcrn8+rt7R1RP16P58m280QWLFggSePueMbjcc2ePVvz589XV1eX5s2bp+9973tn9Fie9QMoHo9r/vz5Wr9+/fDXyuWy1q9fr46ODo8rG1uDg4PavXu3WltbfS9lTMyYMUMtLS0jjmt/f79efvnlCX1cpXc/9ffo0aPj6tgGQaA777xT69at00svvaQZM2aM+P78+fMVi8VGHM+dO3dq79694+p4nmo7T2T79u2SNK6O54mUy2XlcrkzeyxH9SUNY+SJJ54IEolEsGbNmuCNN94IbrvttqCuri7o7u72vbRR8zd/8zfBhg0bgj179gT/+Z//GSxatChobGwMDh065Htpp21gYCB45ZVXgldeeSWQFHznO98JXnnlleDtt98OgiAIHnzwwaCuri54+umngx07dgTXXXddMGPGjCCTyXheuc2HbefAwEDwla98Jdi8eXOwZ8+e4MUXXww++clPBueee26QzWZ9L93ZHXfcEaRSqWDDhg3BwYMHh29DQ0PDNbfffnswbdq04KWXXgq2bt0adHR0BB0dHR5XbXeq7dy1a1fwwAMPBFu3bg327NkTPP3008HMmTODK6+80vPKbb7+9a8HGzduDPbs2RPs2LEj+PrXvx6EQqHgP/7jP4IgOHPHclwMoCAIgh/84AfBtGnTgng8Hlx22WXBli1bfC9pVN14441Ba2trEI/HgylTpgQ33nhjsGvXLt/L+kh+8YtfBJI+cFu+fHkQBO++FPub3/xm0NzcHCQSiWDhwoXBzp07/S76NHzYdg4NDQXXXHNNMHny5CAWiwXTp08Pbr311nH3y9OJtk9S8Nhjjw3XZDKZ4K/+6q+CSZMmBZWVlcHnP//54ODBg/4WfRpOtZ179+4NrrzyyqC+vj5IJBLB7Nmzg7/9278N+vr6/C7c6C//8i+D6dOnB/F4PJg8eXKwcOHC4eETBGfuWPJxDAAAL87654AAABMTAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxf8H/IlN+ZvxeyIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image type: <class 'PIL.Image.Image'>\n",
            "label: 6\n"
          ]
        }
      ],
      "source": [
        "# Train data 이미지 및 레이블 확인\n",
        "image, label = trainset[0]\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "print(f'image type: {type(image)}')\n",
        "print(f'label: {label}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m14SHtCgoZNK"
      },
      "source": [
        "## 입력 자료구조 변환\n",
        "* PyTorch에서 neural network에 대한 모든 입력은 PyTorch에서 정의한 Tensor라는 자료구조를 사용해야 함\n",
        "* 위 셀에서 image type은 <class 'PIL.Image.Image'>이므로 변형 필요\n",
        "* TF.to_tensor 함수 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4c3GRYonn0J",
        "outputId": "7f759acb-df33-443b-e6b7-4c71e1d09c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image type: <class 'torch.Tensor'>\n",
            "image size: torch.Size([3, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# PIL.Image.Image -> torch.Tensor로 변경\n",
        "image = TF.to_tensor(image)\n",
        "print(f'image type: {type(image)}')\n",
        "print(f'image size: {image.size()}') # 3채널(R,G,B), 32(height,세로), 32(width,가로)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9bFyyU5K3y"
      },
      "source": [
        "## pre-processing\n",
        "* 이미지 데이터에 Multi-Layer Perceptron (MLP) 적용하기 위한 pre-processing\n",
        "* (review) nn.Linear의 인풋 데이터는 2차원 행렬 형태를 가져야 한다.\n",
        "* 하지만 CIFAR10과 같은 이미지 데이터의 경우 height, width 외에 channel이라는 차원을 가지고 있다. (즉 3차원 데이터)\n",
        "* 따라서 이러한 형태를 2차원 형태로 변환해주는 flattening 과정이 필요하다. (flatten 메소드 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTe99wwnP_pC",
        "outputId": "83822c8d-0c59-4b77-c7b9-dbd4cf565ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image size 확인: torch.Size([3, 32, 32])\n",
            "flattened image size 확인: torch.Size([3, 1024])\n"
          ]
        }
      ],
      "source": [
        "# flatten, permute\n",
        "image, label = trainset[1214] # train data 1개 load\n",
        "image = TF.to_tensor(image)\n",
        "print(f'image size 확인: {image.size()}')\n",
        "image_flat = image.flatten(start_dim=1, end_dim=2) # start_dim과 end_dim는 flatten를 수행할 때 시작 차원과 끝 차원을 지정. 여기서 start_dim=1, end_dim=2는 두 번째 차원부터 세 번째 차원까지 평탄화됨을 나타냄.\n",
        "print(f'flattened image size 확인: {image_flat.size()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u6Gm_2V4nku"
      },
      "source": [
        "* Dataset 클래스를 새롭게 정의하여 CIFAR10 데이터셋에서 이미지를 불러올 때마다 flatten과 permute를 자동으로 수행하게 한다. 아래와 같이 선언 (코드 수정할 필요 없음)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7MyKuhO3GXD",
        "outputId": "18878a1a-e238-4eba-9f0e-90bf65b7a2dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image size 확인: torch.Size([3, 1024])\n"
          ]
        }
      ],
      "source": [
        "class Cifar10Dataset(Dataset):\n",
        "  def __init__(self, dataset, train=True):\n",
        "    super(Cifar10Dataset, self).__init__()\n",
        "    self.dataset = dataset\n",
        "    self.train = train\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image, label = self.dataset[index]\n",
        "    image = TF.to_tensor(image)\n",
        "    image = image.flatten(start_dim=1, end_dim=2)\n",
        "    # image = image.permute(1,0)\n",
        "    return image, label\n",
        "\n",
        "train_data = Cifar10Dataset(trainset, train=True)\n",
        "test_data = Cifar10Dataset(testset, train=False)\n",
        "\n",
        "image, label = train_data[1234]\n",
        "print(f'image size 확인: {image.size()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAGM9L5S45Ou"
      },
      "source": [
        "## DataLoader\n",
        "\n",
        "* 위처럼 정의된 Dataset에서 데이터를 한 번에 batch_size만큼 불러올 수 있는 기능\n",
        "* 아래와 같이 선언 (코드 수정할 필요 없음)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROhJ2RSTZIUN",
        "outputId": "80c0f0d0-eca9-43cd-8d41-c9652f57a54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image size 확인: torch.Size([128, 3, 1024])\n",
            "label size 확인: torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "# DataLoader 사용\n",
        "train_loader = DataLoader(train_data, batch_size=128, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=128, shuffle=False, pin_memory=True)\n",
        "\n",
        "image, label = next(iter(train_loader)) #  첫 번째 미니배치를 가져옴\n",
        "print(f'image size 확인: {image.size()}') # [128, 3, 1024] == [batch_size, channel(RGB), height*width]\n",
        "print(f'label size 확인: {label.size()}') # [128] == [batch_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfKFs8Rb7qCc"
      },
      "source": [
        "## 모델 학습을 위한 model, optimizer, loss function 정의\n",
        "* 학습 후 테스트 진행\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Gc37nVwc22hk"
      },
      "outputs": [],
      "source": [
        "# model, optimizer, loss function 정의 예시\n",
        "torch.random.manual_seed(100)\n",
        "model = CustomMLP(num_layers=5, out_feat_list=[1024,256,64,16,10], act='relu').to(device) # 문제3에서 생성한 CustomMLP 사용\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Adam optimizer. lr: learning rate\n",
        "                                                           # model.parameters()는 모델의 학습 가능한 모든 매개변수들을 전달하는 역할\n",
        "                                                           # learning rate는 가중치 업데이트 단계에서 사용\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "                                  # 크로스 엔트로피 손실 함수: 다중 클래스 분류(multi-class classification) 문제에 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX3jQVIT91Ha",
        "outputId": "51f937cf-cd8f-4991-b00e-92c4bda16374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 44.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 average loss: 2.154045\n",
            "1 average accuracy: 20.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 average loss: 2.047038\n",
            "2 average accuracy: 27.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 47.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 average loss: 1.986289\n",
            "3 average accuracy: 29.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 42.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 average loss: 1.927736\n",
            "4 average accuracy: 32.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 average loss: 1.891010\n",
            "5 average accuracy: 33.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 48.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 average loss: 1.856721\n",
            "6 average accuracy: 34.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 41.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 average loss: 1.826869\n",
            "7 average accuracy: 35.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 42.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 average loss: 1.799609\n",
            "8 average accuracy: 36.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 46.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 average loss: 1.777067\n",
            "9 average accuracy: 37.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 41.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 average loss: 1.752938\n",
            "10 average accuracy: 38.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 47.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 average loss: 1.731115\n",
            "11 average accuracy: 39.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 42.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 average loss: 1.709890\n",
            "12 average accuracy: 40.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 41.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 average loss: 1.690273\n",
            "13 average accuracy: 41.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 47.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 average loss: 1.670232\n",
            "14 average accuracy: 41.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 41.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 average loss: 1.654112\n",
            "15 average accuracy: 42.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 average loss: 1.637611\n",
            "16 average accuracy: 43.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 44.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 average loss: 1.616711\n",
            "17 average accuracy: 43.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 41.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 average loss: 1.605795\n",
            "18 average accuracy: 44.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 48.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 average loss: 1.588607\n",
            "19 average accuracy: 44.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 41.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 average loss: 1.577259\n",
            "20 average accuracy: 45.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# model training 예시 코드\n",
        "from tqdm import tqdm\n",
        "for epoch in range(20):\n",
        "  total_loss = 0.0\n",
        "  total_right = 0\n",
        "  for i, (image, label) in enumerate(tqdm(train_loader)):\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # 모델 label 분류 예측\n",
        "    output = model(image)\n",
        "    output = output.max(1)[0]\n",
        "\n",
        "    # loss 계산\n",
        "    loss = criterion(output, label.long())\n",
        "    total_loss += loss\n",
        "\n",
        "    # 정답을 맞춘 개수 계산\n",
        "    right = (output.max(1)[1] == label).sum()\n",
        "    total_right += right\n",
        "\n",
        "    # Back-Propagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i==len(train_loader)-1:\n",
        "      print(f'{epoch+1} average loss: {total_loss/len(train_loader):.6f}')\n",
        "      print(f'{epoch+1} average accuracy: {total_right/len(train_loader.dataset)*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PqWODPLWVJW",
        "outputId": "055d81d1-d8e8-4806-d52e-4972d99552a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:01<00:00, 52.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST average accuracy: 38.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# test 예시 코드\n",
        "total_right = 0\n",
        "for i, (image, label) in enumerate(tqdm(test_loader)):\n",
        "  image = image.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  # 모델 label 분류 예측\n",
        "  output = model(image)\n",
        "  output = output.max(1)[0]\n",
        "\n",
        "  # 정답을 맞춘 개수 계산\n",
        "  right = (output.max(1)[1] == label).sum()\n",
        "  total_right += right\n",
        "\n",
        "  if i==len(test_loader)-1:\n",
        "    print(f'TEST average accuracy: {total_right/len(test_loader.dataset)*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J4PjZWyDQtv"
      },
      "source": [
        "## ★ 문제4\n",
        "### 아래 조건에 맞게 코드를 작성하고 test 정확도 40% 이상 달성을 목표로 모델을 구현하시오.\n",
        "\n",
        "### 조건\n",
        "* model은 반드시 문제3에서 생성한 CustomMLP를 사용하도록 한다.\n",
        "* num_layers는 10이 넘지 않아야 한다.\n",
        "* out_feat_list에는 1024를 넘는 수가 없어야 한다.\n",
        "* activation function은 Sigmoid, ReLU, tanh 외에 소개되지 않은 것을 사용해도 상관 없다. 소개되지 않은 activation function을 사용할 경우 select_act 함수를 적절히 수정하도록 한다.\n",
        "* 아래 코드에서 수정해도 되는 것: CustomMLP의 모든 파라미터(단 위 조건에 맞아야 함), SEED, LEARNING_RATE, optimizer\n",
        "* 아래 코드에서 수정하면 안 되는 것: criterion, TRAINING PHASE, TEST PHASE\n",
        "* 성능평가: 테스트 정확도 40% 이상이면 만점, 40% 미만은 1% 구간 별로 1점씩 감점\n",
        "(예: 39.5% -> 1점 감점 38.7% -> 2점 감점)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "2rE9cdrwDQR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52021c2-a5b8-4a1e-ecdb-670b57c38ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 average loss: 2.387727\n",
            "1 average accuracy: 13.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 average loss: 2.065557\n",
            "2 average accuracy: 23.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 average loss: 1.989086\n",
            "3 average accuracy: 27.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 average loss: 1.927838\n",
            "4 average accuracy: 29.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 42.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 average loss: 1.875292\n",
            "5 average accuracy: 32.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 43.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 average loss: 1.837768\n",
            "6 average accuracy: 33.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:12<00:00, 31.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 average loss: 1.800957\n",
            "7 average accuracy: 35.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 45.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 average loss: 1.769212\n",
            "8 average accuracy: 36.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 average loss: 1.739326\n",
            "9 average accuracy: 37.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 average loss: 1.711000\n",
            "10 average accuracy: 38.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 44.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 average loss: 1.685491\n",
            "11 average accuracy: 39.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 39.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 average loss: 1.660815\n",
            "12 average accuracy: 40.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 40.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 average loss: 1.636583\n",
            "13 average accuracy: 41.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 43.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 average loss: 1.607401\n",
            "14 average accuracy: 42.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 39.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 average loss: 1.587101\n",
            "15 average accuracy: 43.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 42.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 average loss: 1.561242\n",
            "16 average accuracy: 44.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 42.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 average loss: 1.537474\n",
            "17 average accuracy: 45.27%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:10<00:00, 38.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 average loss: 1.514397\n",
            "18 average accuracy: 46.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:08<00:00, 43.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 average loss: 1.491398\n",
            "19 average accuracy: 46.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:09<00:00, 42.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 average loss: 1.467324\n",
            "20 average accuracy: 47.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:01<00:00, 53.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "TEST average accuracy: 43.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "####################################### TODO #######################################\n",
        "SEED = 50 # can be changed\n",
        "LEARNING_RATE = 0.0009 # can be changed\n",
        "torch.random.manual_seed(SEED)\n",
        "model = CustomMLP(num_layers=8, out_feat_list=[1024,256,64,16,10, 128, 256, 512], act='leakyrelu').to(device) # can be changed (but meet conditions above)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) # can be changed\n",
        "\n",
        "####################################################################################\n",
        "criterion = nn.CrossEntropyLoss() # NEVER CHANGE!!\n",
        "\n",
        "#################################### TRAINING PHASE // NEVER EDIT!! ####################################\n",
        "from tqdm import tqdm\n",
        "for epoch in range(20):\n",
        "  total_loss = 0.0\n",
        "  total_right = 0\n",
        "  for i, (image, label) in enumerate(tqdm(train_loader)): # 각 에포크는 train_loader에서 미니배치를 가져와서 학습\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # 모델 label 분류 예측\n",
        "    output = model(image)\n",
        "    output = output.max(1)[0]\n",
        "\n",
        "    # loss 계산\n",
        "    loss = criterion(output, label.long())\n",
        "    total_loss += loss\n",
        "\n",
        "    # 정답을 맞춘 개수 계산\n",
        "    right = (output.max(1)[1] == label).sum()\n",
        "    total_right += right\n",
        "\n",
        "    # Back-Propagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i==len(train_loader)-1:\n",
        "      print(f'{epoch+1} average loss: {total_loss/len(train_loader):.6f}')\n",
        "      print(f'{epoch+1} average accuracy: {total_right/len(train_loader.dataset)*100:.2f}%')\n",
        "#######################################################################################################\n",
        "\n",
        "###################################### TEST PHASE // NEVER EDIT!! #####################################\n",
        "total_right = 0\n",
        "for i, (image, label) in enumerate(tqdm(test_loader)):\n",
        "  image = image.to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  # 모델 label 분류 예측\n",
        "  output = model(image)\n",
        "  output = output.max(1)[0]\n",
        "\n",
        "  # 정답을 맞춘 개수 계산\n",
        "  right = (output.max(1)[1] == label).sum()\n",
        "  total_right += right\n",
        "\n",
        "print()\n",
        "print()\n",
        "print(f'TEST average accuracy: {total_right/len(test_loader.dataset)*100:.2f}%')\n",
        "#######################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Vh0f7l0KvHn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}